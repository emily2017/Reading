# Contemporary issues in methodology and practice

In 1959, statistician Theodore Sterling examined the results of psychological studies and discovered that 97% of them supported their initial hypotheses, implying a possible publication bias.[196][197][198] Similarly, Fanelli (2010)[199] found that 91.5% of psychiatry/psychology studies confirmed the effects they were looking for, and concluded that the odds of this happening (a positive result) was around five times higher than in fields such as space- or geosciences. Fanelli argues that this is because researchers in "softer" sciences have fewer constraints to their conscious and unconscious biases.

Some popular media outlets have in recent years spotlighted a replication crisis in psychology, arguing that many findings in the field cannot be reproduced. Repeats of some famous studies have not reached the same conclusions, and some researchers have been accused of outright fraud in their results. Focus on this issue has led to renewed efforts in the discipline to re-test important findings.[200][201][202][203] As many as two-thirds of highly publicized findings in psychology have failed to be replicated.[204] One subfield of psychology that has largely been unaffected by the replication crisis has been behavioral genetics,[205] with the exception of the candidate gene and candidate gene by environment interaction research on behavior and mental illness.[206]

Some critics view statistical hypothesis testing as misplaced. Psychologist and statistician Jacob Cohen wrote in 1994 that psychologists routinely confuse statistical significance with practical importance, enthusiastically reporting great certainty in unimportant facts.[207] Some psychologists have responded with an increased use of effect size statistics, rather than sole reliance on the Fisherian p < .05 significance criterion (whereby an observed difference is deemed "statistically significant" if an effect of that size or larger would occur with 5% -or less- probability in independent replications, assuming the truth of the null-hypothesis of no difference between the treatments).[citation needed]

The GRIM test has been applied to 260 articles published in Psychological Science, the Journal of Experimental Psychology: General, and the Journal of Personality and Social Psychology. Of these articles, 71 were amenable to GRIM test analysis; 36 of these contained at least one impossible value and 16 contained multiple impossible values.[208]

In 2010, a group of researchers reported a systemic bias in psychology studies towards WEIRD ("western, educated, industrialized, rich and democratic") subjects.[209] Although only 1/8 people worldwide fall into the WEIRD classification, the researchers claimed that 60–90% of psychology studies are performed on WEIRD subjects. The article gave examples of results that differ significantly between WEIRD subjects and tribal cultures, including the Müller-Lyer illusion.

Some observers perceive a gap between scientific theory and its application—in particular, the application of unsupported or unsound clinical practices.[210] Critics say there has been an increase in the number of mental health training programs that do not instill scientific competence.[211] One skeptic asserts that practices, such as "facilitated communication for infantile autism"; memory-recovery techniques including body work; and other therapies, such as rebirthing and reparenting, may be dubious or even dangerous, despite their popularity.[212] In 1984, Allen Neuringer made a similar point[vague] regarding the experimental analysis of behavior.[213] Psychologists, sometimes divided along the lines of laboratory vs. clinic, continue to debate these issues.[214]
